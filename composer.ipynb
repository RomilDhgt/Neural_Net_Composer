{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The RNN Composer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the neccessary libraries and tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Romil\\anaconda3\\envs\\virtualENV\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MIDI File Processing\n",
    "\n",
    "This code block utilizes the Music21 library to parse MIDI files, extracting musical notes and chords. It compiles these elements into a sequential list, encoding single notes by their pitch and chords by joining the normal order of their notes with dots. The resulting list, 'notes,' serves as input data for subsequent steps in a process involving neural network training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store notes and chords\n",
    "notes = []\n",
    "\n",
    "# Iterate over all MIDI files in the \"music_data\" directory\n",
    "for file in glob.glob(\"music_data/*.mid\"):\n",
    "    # Parse the MIDI file using Music21's converter to get a list of notes and chords in the file\n",
    "    midi = converter.parse(file)\n",
    "    parsed_notes = None\n",
    "    \n",
    "    try:\n",
    "        # Attempt to partition the music by instrument\n",
    "        s2 = instrument.partitionByInstrument(midi)\n",
    "        parsed_notes = s2.parts[0].recurse() \n",
    "    except:\n",
    "        # If partitioning by instrument fails, use flat.notes\n",
    "        parsed_notes = midi.flat.notes\n",
    "    \n",
    "    # Iterate over each note or chord in the parsed notes\n",
    "    for element in parsed_notes:\n",
    "        # Check if the element is a single note\n",
    "        if isinstance(element, note.Note):\n",
    "            # Append the pitch of the note to the notes list\n",
    "            notes.append(str(element.pitch))\n",
    "        # Check if the element is a chord\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            # Append the chord by joining the normal order of its notes with dots\n",
    "            notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "# Calculate the number of unique notes and chords in the list\n",
    "num = len(set(notes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation and Encoding \n",
    "\n",
    "This code block prepares data for a neural network by creating input sequences and corresponding outputs for music generation. It sets the input sequence length to 100 notes/chords, creates a numerical mapping for pitchnames, and iterates through the 'notes' list to generate training data. The input sequences are then reshaped, normalized, and the outputs are one-hot encoded to facilitate training the neural network for music composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the length of each input sequence to 100 notes/chords\n",
    "sequence_len = 100\n",
    "\n",
    "# Create a sorted set of unique pitchnames from the 'notes' list\n",
    "pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "# Create a dictionary to map each pitchname to a numerical value\n",
    "note_in_num = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "# Initialize empty lists to store input sequences and their respective outputs\n",
    "net_input = []\n",
    "net_output = []\n",
    "\n",
    "# Iterate over the 'notes' list to create input sequences and outputs\n",
    "for i in range(0, len(notes) - sequence_len, 1):\n",
    "    seq_in = notes[i:i + sequence_len]\n",
    "    seq_out = notes[i + sequence_len]\n",
    "    # Convert the input sequence and output to numerical values using the mapping dictionary\n",
    "    net_input.append([note_in_num[char] for char in seq_in])\n",
    "    net_output.append([note_in_num[seq_out]])\n",
    "\n",
    "# Calculate the total number of input patterns\n",
    "num_patterns = len(net_input)\n",
    "\n",
    "# Reshape the input data to fit the neural network input shape\n",
    "norm_input = numpy.reshape(net_input, (num_patterns, sequence_len, 1))\n",
    "\n",
    "# Normalize the input data by dividing it by the total number of unique pitchnames\n",
    "norm_input = norm_input / float(num)\n",
    "\n",
    "# One-hot encode the output data\n",
    "net_output = to_categorical(net_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training \n",
    "\n",
    "This code block defines a neural network for music generation using Keras with three LSTM layers, Dropout layers for regularization, Dense layers for 'tighter' input and output connections, and an Activation layer. The model is compiled with categorical cross entropy loss and RMSprop optimizer. During training, model checkpoints are implemented to save weights after each epoch, allowing for the flexibility to stop training at any point without losing progress, and the final trained model is saved to a file named 'my_model.hdf5'.\n",
    "\n",
    "NOTE: Only run this step to if you wish to train the model yourself on a powerful GPU, otherwise use the weights that I have already made. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model architecture using Keras Sequential API\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first LSTM layer with 512 nodes, input shape based on net_input dimensions, recurrent dropout, and returning sequences\n",
    "model.add(LSTM(\n",
    "    512,\n",
    "    input_shape=(norm_input.shape[1], norm_input.shape[2]),\n",
    "    recurrent_dropout=0.3,\n",
    "    return_sequences=True\n",
    "))\n",
    "\n",
    "# Add the second LSTM layer with 512 nodes, recurrent dropout, and returning sequences\n",
    "model.add(LSTM(\n",
    "    512,\n",
    "    return_sequences=True,\n",
    "    recurrent_dropout=0.3\n",
    "))\n",
    "\n",
    "# Add the third LSTM layer with 512 nodes\n",
    "model.add(LSTM(512))\n",
    "\n",
    "# Add Batch Normalization to improve training stability\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add Dropout layer for regularization to prevent overfitting\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Add a Dense layer with 256 nodes\n",
    "model.add(Dense(256))\n",
    "\n",
    "# Apply Rectified Linear Unit (ReLU) activation function\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Add Batch Normalization for improved convergence\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add Dropout layer for regularization\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Add the final Dense layer with nodes equal to the number of unique pitchnames\n",
    "model.add(Dense(num))\n",
    "\n",
    "# Apply softmax activation function for multi-class classification\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile the model using categorical cross entropy loss and RMSprop optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "# Define a ModelCheckpoint callback to save the model weights during training\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\",\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Create a list of callbacks, including the ModelCheckpoint\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Train the model using the prepared input sequences and outputs, with 100 epochs and a batch size of 128\n",
    "model.fit(net_input, net_output, epochs=100, batch_size=128, callbacks=callbacks_list)\n",
    "\n",
    "# Save the trained model to a file\n",
    "model.save('my_model.hdf5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Trained Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model architecture using Keras Sequential API\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first LSTM layer with 512 nodes, input shape based on net_input dimensions, recurrent dropout, and returning sequences\n",
    "model.add(LSTM(\n",
    "    512,\n",
    "    input_shape=(norm_input.shape[1], norm_input.shape[2]),\n",
    "    recurrent_dropout=0.3,\n",
    "    return_sequences=True\n",
    "))\n",
    "# Add the second LSTM layer with 512 nodes, recurrent dropout, and returning sequences\n",
    "model.add(LSTM(\n",
    "    512,\n",
    "    return_sequences=True,\n",
    "    recurrent_dropout=0.3\n",
    "))\n",
    "\n",
    "# Add the third LSTM layer with 512 nodes\n",
    "model.add(LSTM(512))\n",
    "\n",
    "# Add Batch Normalization to improve training stability\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add Dropout layer for regularization to prevent overfitting\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Add a Dense layer with 256 nodes\n",
    "model.add(Dense(256))\n",
    "\n",
    "# Apply Rectified Linear Unit (ReLU) activation function\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Add Batch Normalization for improved convergence\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add Dropout layer for regularization\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Add the final Dense layer with nodes equal to the number of unique pitchnames\n",
    "model.add(Dense(num))\n",
    "\n",
    "# Apply softmax activation function for multi-class classification\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile the model using categorical cross entropy loss and RMSprop optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "# Load the weights to each node\n",
    "model.load_weights(\"weights/weights-improvement-99-0.3726-bigger.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Notes\n",
    "\n",
    "This code block leverages a trained neural network to generate a sequence of 500 musical notes. It initiates the process by randomly selecting an index from the input data, ensuring varied results upon rerun. The code iteratively predicts and decodes notes using the trained model, updating the input pattern for each step in the generation process. The int_to_note dictionary is crucial for decoding numerical predictions back into categorical note values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a random index as the starting point for note generation\n",
    "start = numpy.random.randint(0, len(net_input)-1)\n",
    "\n",
    "# Create a dictionary mapping numerical values to pitchnames for decoding the network output\n",
    "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "# Initialize the input pattern with the randomly chosen starting point\n",
    "pattern = net_input[start]\n",
    "prediction_output = []\n",
    "\n",
    "# Generate 500 notes using the trained model\n",
    "for note_index in range(500):\n",
    "    # Reshape the input pattern to fit the neural network input shape\n",
    "    prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    # Normalize the input data\n",
    "    prediction_input = prediction_input / float(num)\n",
    "\n",
    "    # Make a prediction using the trained model\n",
    "    prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "    # Find the index of the highest predicted value\n",
    "    index = numpy.argmax(prediction)\n",
    "    # Decode the numerical value to a pitchname using the mapping dictionary\n",
    "    result = int_to_note[index]\n",
    "    # Append the decoded pitchname to the prediction output\n",
    "    prediction_output.append(result)\n",
    "\n",
    "    # Update the input pattern by adding the index and removing the first element\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the midi file\n",
    "\n",
    "This code block takes the output from the neural network, which consists of encoded representations of notes and chords, and decodes them to create a sequence of Note and Chord objects. The offset is incremented for each iteration to avoid note stacking in the final composition. The resulting musical composition is then saved as a MIDI file named '59_epoch_composition.mid'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'59_epoch_composition.mid'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize offset and an empty list to store output notes\n",
    "offset = 0\n",
    "output_notes = []\n",
    "\n",
    "# Create note and chord objects based on the values generated by the model\n",
    "for pattern in prediction_output:\n",
    "    # Check if the pattern represents a chord\n",
    "    if ('.' in pattern) or pattern.isdigit():\n",
    "        # If it's a chord, split the string into an array of notes\n",
    "        notes_in_chord = pattern.split('.')\n",
    "        notes = []\n",
    "        # Loop through the notes and create Note objects for each\n",
    "        for current_note in notes_in_chord:\n",
    "            new_note = note.Note(int(current_note))\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            notes.append(new_note)\n",
    "        # Create a Chord object with the notes and set its offset\n",
    "        new_chord = chord.Chord(notes)\n",
    "        new_chord.offset = offset\n",
    "        # Append the Chord object to the output notes list\n",
    "        output_notes.append(new_chord)\n",
    "    # If the pattern represents a single note\n",
    "    else:\n",
    "        # Create a Note object using the pitch from the pattern\n",
    "        new_note = note.Note(pattern)\n",
    "        new_note.offset = offset\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        # Append the Note object to the output notes list\n",
    "        output_notes.append(new_note)\n",
    "\n",
    "    # Increase offset for each iteration to prevent note stacking\n",
    "    offset += 0.5\n",
    "\n",
    "# Create a stream of Note and Chord objects\n",
    "midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "# Write the generated music to a MIDI file\n",
    "midi_stream.write('midi', fp='59_epoch_composition.mid')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
